{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzxTJEZi6NvaBMXW/8ipvZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dreamingv-oid/CS290/blob/main/Penguins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6pjR6Yac82H",
        "outputId": "c8a83606-2df9-45c7-b79a-1450d48a4d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
            "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
            "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
            "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
            "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
            "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
            "\n",
            "   body_mass_g     sex  year  \n",
            "0       3750.0    male  2007  \n",
            "1       3800.0  female  2007  \n",
            "2       3250.0  female  2007  \n",
            "3          NaN     NaN  2007  \n",
            "4       3450.0  female  2007  \n"
          ]
        }
      ],
      "source": [
        "#pip install palmerpenguins\n",
        "from palmerpenguins import load_penguins\n",
        "import pandas as pd\n",
        "\n",
        "# Load the penguins dataset\n",
        "penguins = load_penguins()\n",
        "\n",
        "# Convert to pandas DataFrame if needed\n",
        "df = pd.DataFrame(penguins)\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from palmerpenguins import load_penguins\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load the penguins dataset\n",
        "penguins = load_penguins()\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame(penguins)\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=[\"species\"])\n",
        "y = df[\"species\"]\n",
        "\n",
        "# Encode categorical variables (like island and sex)\n",
        "X_encoded = pd.get_dummies(X, columns=[\"island\", \"sex\"])\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Function to calculate Euclidean distance\n",
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "# k-NN classifier implementation\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict(x) for x in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        # Compute distances between x and all training samples\n",
        "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        # Get the k nearest samples\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        # Access y_train using iloc to ensure numerical indexing\n",
        "        k_nearest_labels = [self.y_train.iloc[i] for i in k_indices]\n",
        "        # Majority vote\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "# Instantiate the classifier\n",
        "knn = KNN(k=5)\n",
        "\n",
        "# Fit the model\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OBddIzxeTdd",
        "outputId": "7f06faac-226d-4b01-89b5-b36e6faeb6ed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from palmerpenguins import load_penguins\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Load the penguins dataset\n",
        "penguins = load_penguins()\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame(penguins)\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert species to binary classification: Adelie (1) vs. not Adelie (0)\n",
        "df['species'] = np.where(df['species'] == 'Adelie', 1, 0)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=[\"species\"])\n",
        "y = df[\"species\"]\n",
        "\n",
        "# Encode categorical variables (like island and sex)\n",
        "X_encoded = pd.get_dummies(X, columns=[\"island\", \"sex\"])\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# (a) Logistic Regression\n",
        "print(\"\\nLogistic Regression\")\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
        "evaluate_model(y_test, y_pred_log_reg)\n",
        "\n",
        "# (b) Support Vector Machine (SVM)\n",
        "print(\"\\nSupport Vector Machine (SVM)\")\n",
        "svm_model = SVC(kernel='linear', random_state=42)  # Linear kernel for binary classification\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_scaled)\n",
        "evaluate_model(y_test, y_pred_svm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2daaQKcfOMr",
        "outputId": "9d689c74-bc40-4bd7-b8de-f529fa14aad1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression\n",
            "Accuracy: 0.9900\n",
            "Precision: 0.9796\n",
            "Recall: 1.0000\n",
            "F1 Score: 0.9897\n",
            "Confusion Matrix:\n",
            "[[51  1]\n",
            " [ 0 48]]\n",
            "\n",
            "Support Vector Machine (SVM)\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n",
            "Confusion Matrix:\n",
            "[[52  0]\n",
            " [ 0 48]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from palmerpenguins import load_penguins\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Load the penguins dataset\n",
        "penguins = load_penguins()\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "df = pd.DataFrame(penguins)\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=[\"species\"])\n",
        "y = df[\"species\"]\n",
        "\n",
        "# Encode categorical variables (like island and sex)\n",
        "X_encoded = pd.get_dummies(X, columns=[\"island\", \"sex\"])\n",
        "\n",
        "# Encode target variable (species)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # Convert species names to numeric labels\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision (weighted): {precision:.4f}\")\n",
        "    print(f\"Recall (weighted): {recall:.4f}\")\n",
        "    print(f\"F1 Score (weighted): {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# (a) Softmax Regression (Multinomial Logistic Regression)\n",
        "print(\"\\nSoftmax Regression (Multinomial Logistic Regression)\")\n",
        "softmax_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42, max_iter=500)\n",
        "softmax_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_softmax = softmax_reg.predict(X_test_scaled)\n",
        "evaluate_model(y_test, y_pred_softmax)\n",
        "\n",
        "# (b) Stochastic Gradient Descent (SGD) Classifier\n",
        "print(\"\\nStochastic Gradient Descent (SGD) Classifier\")\n",
        "sgd_clf = SGDClassifier(loss='log_loss', random_state=42, max_iter=1000, tol=1e-3) # Changed loss to 'log_loss'\n",
        "sgd_clf.fit(X_train_scaled, y_train)\n",
        "y_pred_sgd = sgd_clf.predict(X_test_scaled)\n",
        "evaluate_model(y_test, y_pred_sgd)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AXIw7A8fbVS",
        "outputId": "8edee64a-9160-4b19-c1d9-58c310711b2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Softmax Regression (Multinomial Logistic Regression)\n",
            "Accuracy: 0.9900\n",
            "Precision (weighted): 0.9902\n",
            "Recall (weighted): 0.9900\n",
            "F1 Score (weighted): 0.9899\n",
            "Confusion Matrix:\n",
            "[[48  0  0]\n",
            " [ 1 22  0]\n",
            " [ 0  0 29]]\n",
            "\n",
            "Stochastic Gradient Descent (SGD) Classifier\n",
            "Accuracy: 1.0000\n",
            "Precision (weighted): 1.0000\n",
            "Recall (weighted): 1.0000\n",
            "F1 Score (weighted): 1.0000\n",
            "Confusion Matrix:\n",
            "[[48  0  0]\n",
            " [ 0 23  0]\n",
            " [ 0  0 29]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}