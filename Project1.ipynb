{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVnuphS/eIWABxidoeBliV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dreamingv-oid/CS290/blob/main/Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WeFDJQV2CaO_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.dates as mdates\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n"
      ]
    },
    {
      "source": [
        "def Attribute_selection_method(df, target_var, criterion):\n",
        "    # Splitting features and target variable\n",
        "    X = df.drop(target_var, axis=1)\n",
        "    y = df[target_var]\n",
        "\n",
        "    # Identify categorical columns\n",
        "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    # One-hot encode categorical features\n",
        "    if len(categorical_cols) > 0:\n",
        "        X = pd.get_dummies(X, columns=categorical_cols)\n",
        "\n",
        "    # Use DecisionTreeClassifier instead of DecisionTreeRegressor\n",
        "    if criterion == \"entropy\":\n",
        "        model = DecisionTreeClassifier(criterion=\"entropy\")  # Using entropy criterion\n",
        "    elif criterion == \"gini\":\n",
        "        model = DecisionTreeClassifier(criterion=\"gini\")  # Using gini criterion\n",
        "    else:\n",
        "        return \"Invalid criterion\"\n",
        "\n",
        "    # Fit the model to the data\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Get feature importances from the decision tree model\n",
        "    importances = model.feature_importances_\n",
        "\n",
        "    # Find the best feature with the highest importance\n",
        "    best_feature = X.columns[np.argmax(importances)]\n",
        "\n",
        "    return best_feature"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Ws8GyaSwyFL9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Step 1: Data Preprocessing with One-Hot Encoding\n",
        "def preprocess_data(df):\n",
        "    # Separate features and target\n",
        "    X = df.drop('satisfaction', axis=1)\n",
        "    y = df['satisfaction']\n",
        "\n",
        "    # Identify categorical columns\n",
        "    categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "    # Target label encoding (satisfied or dissatisfied)\n",
        "    target_encoder = LabelEncoder()\n",
        "    y = target_encoder.fit_transform(y)  # Binary encoding for the target variable\n",
        "\n",
        "    return X, y, categorical_cols, target_encoder\n",
        "\n",
        "# Load your dataset (assuming it's stored as 'airline_dataset.csv')\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dreamingv-oid/CS290/main/train.csv') # Use raw.githubusercontent.com to access raw data\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "# Preprocess the data\n",
        "X, y, categorical_cols, target_encoder = preprocess_data(df)\n",
        "\n",
        "# Step 2: Define the One-Hot Encoder for Categorical Columns\n",
        "# Create a ColumnTransformer that will One-Hot Encode the categorical columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)  # OneHotEncode categorical columns\n",
        "    ], remainder='passthrough')  # Keep other columns (e.g., numerical columns) as is\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Build a Pipeline with One-Hot Encoding and DecisionTreeClassifier\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),  # Preprocess the data\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))  # Train the decision tree classifier\n",
        "])\n",
        "\n",
        "# Step 5: Cross-Validation and Model Training\n",
        "cv_scores = cross_val_score(clf, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
        "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f}\")\n",
        "\n",
        "# Train the model on the full training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Model Evaluation on the Test Set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 7: Performance Assessment\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=target_encoder.classes_))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "Attribute_selection_method(df,'satisfaction','gini')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "xrqeo165l2SA",
        "outputId": "423122b9-ee92-4c2f-eb6c-ea83dbeb3429"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy: 0.9430\n",
            "Accuracy Score: 0.9473912833630966\n",
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "neutral or dissatisfied       0.95      0.95      0.95     11655\n",
            "              satisfied       0.94      0.94      0.94      9064\n",
            "\n",
            "               accuracy                           0.95     20719\n",
            "              macro avg       0.95      0.95      0.95     20719\n",
            "           weighted avg       0.95      0.95      0.95     20719\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[11107   548]\n",
            " [  542  8522]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Online boarding'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}