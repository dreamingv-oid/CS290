{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsdLQLCqbQEgwXkKlXgyJ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dreamingv-oid/CS290/blob/main/Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeFDJQV2CaO_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.dates as mdates\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n"
      ]
    },
    {
      "source": [
        "def Attribute_selection_method(df, target_var, criterion):\n",
        "    # Splitting features and target variable\n",
        "    X = df.drop(target_var, axis=1)\n",
        "    y = df[target_var]\n",
        "\n",
        "    # Identify categorical columns\n",
        "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "    # One-hot encode categorical features\n",
        "    if len(categorical_cols) > 0:\n",
        "        X = pd.get_dummies(X, columns=categorical_cols)\n",
        "\n",
        "    # Use DecisionTreeClassifier instead of DecisionTreeRegressor\n",
        "    if criterion == \"entropy\":\n",
        "        model = DecisionTreeClassifier(criterion=\"entropy\")  # Using entropy criterion\n",
        "    elif criterion == \"gini\":\n",
        "        model = DecisionTreeClassifier(criterion=\"gini\")  # Using gini criterion\n",
        "    else:\n",
        "        return \"Invalid criterion\"\n",
        "\n",
        "    # Fit the model to the data\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Get feature importances from the decision tree model\n",
        "    importances = model.feature_importances_\n",
        "\n",
        "    # Find the best feature with the highest importance\n",
        "    best_feature = X.columns[np.argmax(importances)]\n",
        "\n",
        "    return best_feature"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Ws8GyaSwyFL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Step 1: Data Preprocessing with One-Hot Encoding\n",
        "def preprocess_data(df):\n",
        "    # Separate features and target\n",
        "    X = df.drop('satisfaction', axis=1)\n",
        "    y = df['satisfaction']\n",
        "\n",
        "    # Identify categorical columns\n",
        "    categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "    # Target label encoding (satisfied or dissatisfied)\n",
        "    target_encoder = LabelEncoder()\n",
        "    y = target_encoder.fit_transform(y)  # Binary encoding for the target variable\n",
        "\n",
        "    return X, y, categorical_cols, target_encoder\n",
        "\n",
        "# Load your dataset (assuming it's stored as 'airline_dataset.csv')\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dreamingv-oid/CS290/main/train.csv') # Use raw.githubusercontent.com to access raw data\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "# Preprocess the data\n",
        "X, y, categorical_cols, target_encoder = preprocess_data(df)\n",
        "\n",
        "# Step 2: Define the One-Hot Encoder for Categorical Columns\n",
        "# Create a ColumnTransformer that will One-Hot Encode the categorical columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)  # OneHotEncode categorical columns\n",
        "    ], remainder='passthrough')  # Keep other columns (e.g., numerical columns) as is\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Build a Pipeline with One-Hot Encoding and DecisionTreeClassifier\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),  # Preprocess the data\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))  # Train the decision tree classifier\n",
        "])\n",
        "\n",
        "# Step 5: Cross-Validation and Model Training\n",
        "cv_scores = cross_val_score(clf, X_train, y_train, cv=5)  # 5-fold cross-validation\n",
        "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f}\")\n",
        "\n",
        "# Train the model on the full training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Model Evaluation on the Test Set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 7: Performance Assessment\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=target_encoder.classes_))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "Attribute_selection_method(df,'satisfaction','gini')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "xrqeo165l2SA",
        "outputId": "4ccc3805-db82-4852-8bd6-bd27375c3466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy: 0.9430\n",
            "Accuracy Score: 0.9473912833630966\n",
            "\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "neutral or dissatisfied       0.95      0.95      0.95     11655\n",
            "              satisfied       0.94      0.94      0.94      9064\n",
            "\n",
            "               accuracy                           0.95     20719\n",
            "              macro avg       0.95      0.95      0.95     20719\n",
            "           weighted avg       0.95      0.95      0.95     20719\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[11107   548]\n",
            " [  542  8522]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Online boarding'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project 2 Task 1"
      ],
      "metadata": {
        "id": "FlXr7KNTK1QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def naive_bayes_classifier(X, y, new_instance):\n",
        "    # Ensure y is a pandas Series and reset indices for alignment\n",
        "    y = pd.Series(y).reset_index(drop=True)\n",
        "    X = X.reset_index(drop=True)\n",
        "\n",
        "    # Calculate class counts and priors\n",
        "    class_counts = y.value_counts().to_dict()\n",
        "    total_count = len(y)\n",
        "    priors = {cls: np.log(count / total_count) for cls, count in class_counts.items()}\n",
        "\n",
        "    # Calculate the likelihoods for each feature per class\n",
        "    likelihoods = {}\n",
        "    feature_values = {col: X[col].unique() for col in X.columns}\n",
        "\n",
        "    for feature in X.columns:\n",
        "        likelihoods[feature] = {}\n",
        "        for cls in class_counts.keys():\n",
        "            X_class = X[y == cls]  # Filter data for the class\n",
        "            feature_counts = X_class[feature].value_counts().to_dict()\n",
        "\n",
        "            # Calculate smoothed likelihoods and store log probabilities\n",
        "            likelihoods[feature][cls] = {\n",
        "                value: np.log((feature_counts.get(value, 0) + 1) / (class_counts[cls] + len(feature_values[feature])))\n",
        "                for value in feature_values[feature]\n",
        "            }\n",
        "\n",
        "    # Calculate posterior probabilities for each class\n",
        "    posteriors = {}\n",
        "\n",
        "    for cls in class_counts.keys():\n",
        "        # Start with the log of the prior probability\n",
        "        posteriors[cls] = priors[cls]\n",
        "\n",
        "        # Add the log likelihoods for each feature\n",
        "        for feature, value in new_instance.items():\n",
        "            if value in likelihoods[feature][cls]:\n",
        "                posteriors[cls] += likelihoods[feature][cls][value]\n",
        "            else:\n",
        "                # Handle unseen values with a small probability\n",
        "                posteriors[cls] += np.log(1 / (class_counts[cls] + len(feature_values[feature])))\n",
        "\n",
        "    # Predict the class with the highest posterior probability\n",
        "    return max(posteriors, key=posteriors.get)\n",
        "\n",
        "\n",
        "# Usage Example\n",
        "# Assuming X and y have been prepared using preprocess_data function\n",
        "new_instance = {'Gender': 'Female', 'Customer Type': 'Loyal Customer', 'Age': 35, 'Class': 'Business'}\n",
        "predicted_class = naive_bayes_classifier(X, y, new_instance)\n",
        "print(\"Predicted Class:\", predicted_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-xYGDiHK000",
        "outputId": "7b0b5886-7f68-4640-e7dd-65bfd1dfc389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2\n",
        "I am using the same dataset here, but I will be training it on the Arrival Delay in minutes feature as the target variable."
      ],
      "metadata": {
        "id": "KYJMuOtGZ-sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the airline dataset\n",
        "url = 'https://raw.githubusercontent.com/dreamingv-oid/CS290/main/train.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Drop rows with missing values for simplicity\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Select the target variable for regression\n",
        "target_var = 'Arrival Delay in Minutes'\n",
        "X = df.drop(columns=[target_var])\n",
        "y = df[target_var]\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# One-hot encode categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ], remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Apply the preprocessing and split the dataset\n",
        "X_encoded = preprocessor.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the DecisionTreeRegressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Output the performance metrics\n",
        "print(\"Performance of DecisionTreeRegressor on the Airline Dataset:\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (R²): {r2:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTx-8uwHaVut",
        "outputId": "36f6bb4a-d62e-4172-ae7b-25b2576c4c86"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance of DecisionTreeRegressor on the Airline Dataset:\n",
            "Mean Squared Error (MSE): 212.42\n",
            "Mean Absolute Error (MAE): 7.62\n",
            "R-squared (R²): 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3"
      ],
      "metadata": {
        "id": "awV1i1VDa-n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Load the airline dataset\n",
        "url = 'https://raw.githubusercontent.com/dreamingv-oid/CS290/main/train.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df.drop(columns=['satisfaction'])\n",
        "y = df['satisfaction']\n",
        "\n",
        "# Encode categorical variables using one-hot encoding\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ], remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the pipeline including preprocessor and classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'classifier__max_depth': [5, 10, 15, None],\n",
        "    'classifier__min_samples_split': [2, 10, 20],\n",
        "    'classifier__min_samples_leaf': [1, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Tuned Model:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['dissatisfied', 'satisfied']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S0fGSVFa9-Y",
        "outputId": "44ad7995-da54-4db4-b520-37a35ddfe36e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "Best Parameters: {'classifier__max_depth': 15, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 20}\n",
            "Accuracy of Tuned Model: 0.9554515179304021\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "dissatisfied       0.95      0.97      0.96     11655\n",
            "   satisfied       0.97      0.93      0.95      9064\n",
            "\n",
            "    accuracy                           0.96     20719\n",
            "   macro avg       0.96      0.95      0.95     20719\n",
            "weighted avg       0.96      0.96      0.96     20719\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4"
      ],
      "metadata": {
        "id": "2Pgtd-wfb7tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "\n",
        "# Train the RandomForestClassifier\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"RandomForestClassifier Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=['dissatisfied', 'satisfied']))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oATT4dBnb-sl",
        "outputId": "8040900f-ffd3-481e-d9f4-66f48948d314"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier Accuracy: 0.9649596988271635\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "dissatisfied       0.96      0.98      0.97     11655\n",
            "   satisfied       0.98      0.94      0.96      9064\n",
            "\n",
            "    accuracy                           0.96     20719\n",
            "   macro avg       0.97      0.96      0.96     20719\n",
            "weighted avg       0.97      0.96      0.96     20719\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[11451   204]\n",
            " [  522  8542]]\n"
          ]
        }
      ]
    }
  ]
}